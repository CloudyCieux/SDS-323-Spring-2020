---
title: "Exercise 2"
output: github_document
always_allow_html: yes
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries, include = FALSE}
library(mosaic)
library(tidyverse)
library(FNN)
library(knitr)
library(kableExtra)
library(reshape)
library(foreach)
```

## KNN Practice

```{r read_and_preprocess, include = FALSE}
sclass = read.csv("sclass.csv")

# Focus first on 350 trim level
sclass350 = subset(sclass, trim == "350")

# Focus next on 65 AMG trim level
sclass65AMG = subset(sclass, trim == "65 AMG")
```

Mercedes S Class vehicles cover a wide range of sub-models, from large luxury sedans to high-performance sports cars. Our goal is to hone in on two specific trim levels for these vehicles, 350 and 65AMG, and attempt to build a predictive model using K-nearest neighbors (KNN) for their price based on their mileage.

<p>&nbsp;</p>

```{r fig.align = 'center', echo = FALSE}
# Look at price vs mileage for this trim
ggplot(data = sclass350) +
  geom_point(mapping = aes(x = mileage, y = price), size = 1, col = "black") +
  labs(title = "Mercedes S Class 350 Trim Price vs. Mileage",
       x = "Mileage (miles)",
       y = "Price ($)",
       caption = "Figure 1: Scatterplot of 416 Mercedes S Class vehicles with 350 trim level comparing their price
       with their mileage.") + 
  theme(plot.title = element_text(hjust = 0.5),
        plot.caption = element_text(size = 10, hjust = 0.5))
```

<p>&nbsp;</p>

```{r fig.align = 'center', echo = FALSE}
# Look at price vs mileage for this trim
ggplot(data = sclass65AMG) +
  geom_point(mapping = aes(x = mileage, y = price), size = 1, col = "black") +
  labs(title = "Mercedes S Class 65 AMG Trim Price vs. Mileage",
       x = "Mileage (miles)",
       y = "Price ($)",
       caption = "Figure 2: Scatterplot of 292 Mercedes S Class vehicles with 65 AMG trim level comparing their price
       with their mileage.") + 
  theme(plot.title = element_text(hjust = 0.5),
        plot.caption = element_text(size = 10, hjust = 0.5))
```

Figures 1 and 2 above show the distributions of price vs. mileage for the two different trim levels. As expected, there is a clear negative relationship between price and mileage, which makes sense as cars with higher mileage are more likely used and therefore cheaper than brand new cars. Of greater interest is the almost complete absence of any points in Figure 1 in the 25,000 - 35,000 price range. Making price predictions here could be problematic with KNN because all the closest neighbors aren't that close in reality.

<p>&nbsp;</p>

Now that we've seen the data, it is time to run KNN on the two data sets. Of upmost importance in KNN is choosing the optimal value for K to fit the data. Therefore, values of K starting from 3 and onward were tested on multiple train/test data set splits, recording the average root mean squared error (RMSE) for each K. From there, the K value that yielded the lowest average RMSE was chosen as the optimal K and used to create a model for obtaining price from mileage.

```{r include = FALSE}
# Calculate size of train/test sets
n350 = nrow(sclass350)
n350_train = floor(0.8 * n350)

# Define a helper function for calculating RMSE
RMSE = function(y, ypred) {
  sqrt(mean(data.matrix((y - ypred) ^ 2)))
}

# Run KNN for increasing values of k
k_low350 = 3
k_high350 = 75
k_seq350 = seq(k_low350, k_high350, by = 1)
n_trials350 = 100

avg_RMSE350 = do(n_trials350)* {
  RMSE_seq350 = numeric(0)
  
  # Create train/test sets
  train_set350 = sample.int(n350, n350_train, replace = FALSE)
  train_data350 = sclass350[train_set350,]
  test_data350 = sclass350[-train_set350,]
  
  train_data350 = arrange(train_data350, mileage)
  
  # Select training/testing features (x) and outcomes (y)
  train_x350 = select(train_data350, mileage)
  train_y350 = as.data.frame(select(train_data350, price))
  test_x350 = select(test_data350, mileage)
  test_y350 = select(test_data350, price)
  
  # Do KNN for different k values and record RMSE
  for (k in k_low350:k_high350) {
    knn_model350 = knn.reg(train_x350, test_x350, train_y350, k)
    RMSE_seq350 = c(RMSE_seq350, RMSE(test_y350, knn_model350$pred))
  }
  
  RMSE_seq350
}

data_avg_RMSE350 = data.frame(avg_means = colMeans(avg_RMSE350), k_seq350)

# Choose the optimal value of k to minimize RMSE and plot fit
optimal_k350 = k_seq350[which.min(data_avg_RMSE350$avg_means)]
v1 = min(data_avg_RMSE350$avg_means)

knn_model350 = knn.reg(train_x350, train_x350, train_y350, optimal_k350)
train_data350$ypred = knn_model350$pred
```

```{r fig.align = 'center', echo = FALSE}
# Plot RMSE vs. K
ggplot(data = data_avg_RMSE350) +
  geom_point(mapping = aes(x = k_seq350, y = avg_means)) +
  geom_path(mapping = aes(x = k_seq350, y = avg_means)) +
  geom_vline(xintercept = optimal_k350) +
  labs(title = "Mercedes S Class 350 Trim RMSE vs. K",
       x = "K",
       y = "RMSE",
       caption = "Figure 3: Curve showing average RMSE after 100 train/test splits for each value of K.
       The vertical line shows the K value with the lowest average RMSE.") + 
  theme(plot.title = element_text(hjust = 0.5),
        plot.caption = element_text(size = 10, hjust = 0.5))

ggplot(data = train_data350) + 
  geom_point(mapping = aes(x = mileage, y = price), color = "grey") + 
  geom_path(mapping = aes(x = mileage, y = ypred), color = "black", size = 1.5) +
  labs(title = "Mercedes S Class 350 Trim Price vs. Mileage",
       x = "Mileage (miles)",
       y = "Price ($)",
       caption = "Figure 4: Mercedes S Class 350 Trim vehicles price vs. mileage fit using KNN with the optimal K value.") + 
  theme(plot.title = element_text(hjust = 0.5),
        plot.caption = element_text(size = 10, hjust = 0.5))
```

<p>&nbsp;</p>

```{r include = FALSE}
# Calculate size of train/test sets
n65AMG = nrow(sclass65AMG)
n65AMG_train = floor(0.8 * n65AMG)

# Run KNN for increasing values of k
k_low65AMG = 3
k_high65AMG = 50
k_seq65AMG = seq(k_low65AMG, k_high65AMG, by = 1)
n_trials65AMG = 100

avg_RMSE65AMG = do(n_trials65AMG)* {
  RMSE_seq65AMG = numeric(0)
  
  # Create train/test sets
  train_set65AMG = sample.int(n65AMG, n65AMG_train, replace = FALSE)
  train_data65AMG = sclass65AMG[train_set65AMG,]
  test_data65AMG = sclass65AMG[-train_set65AMG,]
  
  train_data65AMG = arrange(train_data65AMG, mileage)
  
  # Select training/testing features (x) and outcomes (y)
  train_x65AMG = select(train_data65AMG, mileage)
  train_y65AMG = as.data.frame(select(train_data65AMG, price))
  test_x65AMG = select(test_data65AMG, mileage)
  test_y65AMG = select(test_data65AMG, price)
  
  # Do KNN for different k values and record RMSE
  for (k in k_low65AMG:k_high65AMG) {
    knn_model65AMG = knn.reg(train_x65AMG, test_x65AMG, train_y65AMG, k)
    RMSE_seq65AMG = c(RMSE_seq65AMG, RMSE(test_y65AMG, knn_model65AMG$pred))
  }
  
  RMSE_seq65AMG
}

data_avg_RMSE65AMG = data.frame(avg_means = colMeans(avg_RMSE65AMG), k_seq65AMG)

# Choose the optimal value of k to minimize RMSE and plot fit
optimal_k65AMG = k_seq65AMG[which.min(data_avg_RMSE65AMG$avg_means)]
v2 = min(data_avg_RMSE65AMG$avg_means)

knn_model65AMG = knn.reg(train_x65AMG, train_x65AMG, train_y65AMG, optimal_k65AMG)
train_data65AMG$ypred = knn_model65AMG$pred

RMSE_table = as.data.frame(c(v1, v2))
row.names(RMSE_table) = c("350", "65AMG")
```

```{r fig.align = 'center', echo = FALSE}
# Plot RMSE vs. K
ggplot(data = data_avg_RMSE65AMG) +
  geom_point(mapping = aes(x = k_seq65AMG, y = avg_means)) +
  geom_path(mapping = aes(x = k_seq65AMG, y = avg_means)) +
  geom_vline(xintercept = optimal_k65AMG) +
  labs(title = "Mercedes S Class 65 AMG Trim RMSE vs. K",
       x = "K",
       y = "RMSE",
       caption = "Figure 5: Curve showing average RMSE after 100 train/test splits for each value of K.
       The vertical line shows the K value with the lowest average RMSE.") + 
  theme(plot.title = element_text(hjust = 0.5),
        plot.caption = element_text(size = 10, hjust = 0.5))

ggplot(data = train_data65AMG) + 
  geom_point(mapping = aes(x = mileage, y = price), color = "grey") + 
  geom_path(mapping = aes(x = mileage, y = ypred), color = "black", size = 1.5) +
  labs(title = "Mercedes S Class 65 AMG Trim Price vs. Mileage",
       x = "Mileage (miles)",
       y = "Price ($)",
       caption = "Figure 6: Mercedes S Class 65AMG Trim vehicles price vs. mileage fit using KNN with the optimal K value.") + 
  theme(plot.title = element_text(hjust = 0.5),
        plot.caption = element_text(size = 10, hjust = 0.5))
```

<p>&nbsp;</p>

```{r, echo = FALSE}
kable(RMSE_table, col.names = "RMSE ($)", caption = "Table 1: RMSE of Optimal Fit") %>% kable_styling(position = "center")
```

Using the optimal values of K, the models fit the two graphs quite well. Looking at Figures 3 and 5, it is clear that there is a pretty wide range of near optimal K values for the 65AMG trim level, while the range for the 350 trim level is more narrow. Outside of the range though, the 65AMG trim level experiences a steep increase in RMSE compared to the 350 trim level which increases more steadily. Additionally, the 65AMG trim level has a slightly larger optimal K value than the 350 trim level. This could possibly be a result of the difference in spread of the two different distributions as seen in Figures 1 and 2 or 4 and 6, with the 65AMG having more spread out points than the 350. This could possibly lead to more neighbors being needed in creating the optimal model. Regardless, the difference in optimal K values is not that large, and both trims ended up having an optimal K neither extremely small nor large that fit their data well. 

<p>&nbsp;</p>

## Saratoga House Prices

There are many different factors to take into account when assessing the value of a house, so attempting to predict the market value of houses will require the use of powerful modeling methods. Using the Saratoga, NY data set of house prices, the goal is to combine human intuition and modeling methods to produce a more robust predictive model for the housing market.

<p>&nbsp;</p>

The baseline model that will be used to assess the performance of potential models is a rather simple, but decently performing linear model using several of the main features contained within the data set as seen in Table 2 below. By calculating the RMSE on train/test splits for new models compared to the baseline, we can explicitly track their improvement.

Table 2 - Baseline Model Features            |
-----------------|---------------------------|-----------
Lot Size (acres) | Living Area (sqft)        | Bedrooms
Age              | % College Educated        | Bathrooms
Fireplaces       | Rooms                     | Heating
Fuel             | Central Air               |

My first approach at improving the baseline model was based on intution, simply adding main features and interactions between features that I felt would be important in driving house prices. This worked decently well, leading to mild performance improvements. However, later approaches using forward selection, step selection, and KNN on the data set generated models that showed massive gains in performance that made my "hand-built" model pale in comparison.
```{r, include = FALSE}
data(SaratogaHouses)

# Medium model considered in class
lm_orig = lm(price ~ . - sewer - waterfront - landValue - newConstruction,
             data = SaratogaHouses)

# New model that is "hand-built"
lm_new = lm(price ~ . - sewer - landValue - newConstruction +
              age:livingArea + livingArea:centralAir + livingArea:heating +
              livingArea:fuel + fuel:centralAir + age:centralAir +
              livingArea:fireplaces + rooms:heating + bedrooms:fuel +
              livingArea:rooms + bedrooms:bathrooms,
            data = SaratogaHouses)

# New model using forward selection (extracted final model to cut down on computation)
lm_null = lm(price ~ 1, data = SaratogaHouses)
# lm_forward = step(lm_null, direction = "forward",
#                   scope= ~(lotSize + age + livingArea + pctCollege + bedrooms + 
#                             fireplaces + bathrooms + rooms + heating + fuel + centralAir +
#                             landValue + sewer + newConstruction + waterfront) ^ 2)
lm_forward = lm(price ~ livingArea + landValue + bathrooms + waterfront + newConstruction + 
                  heating + lotSize + age + centralAir + rooms + bedrooms + 
                  landValue:newConstruction + bathrooms:heating + livingArea:bathrooms + 
                  lotSize:age + livingArea:waterfront + landValue:lotSize + 
                  livingArea:centralAir + age:centralAir + livingArea:landValue + 
                  bathrooms:bedrooms + bathrooms:waterfront + heating:bedrooms + 
                  heating:rooms + waterfront:centralAir + waterfront:lotSize + 
                  landValue:age + age:rooms + livingArea:lotSize + lotSize:rooms + 
                  lotSize:centralAir,
                data = SaratogaHouses)

# New model using step selection (extracted final model to cut down on computation)
# lm_step = step(lm_orig, 
#                scope= ~(. + landValue + sewer + newConstruction + waterfront) ^ 3)
lm_step = lm(price ~ lotSize + age + livingArea + pctCollege + bedrooms + 
               fireplaces + bathrooms + rooms + heating + fuel + centralAir + 
               landValue + waterfront + newConstruction + livingArea:centralAir + 
               landValue:newConstruction + bathrooms:heating + livingArea:fuel + 
               pctCollege:fireplaces + lotSize:landValue + fuel:centralAir + 
               age:centralAir + age:pctCollege + livingArea:waterfront + 
               fireplaces:waterfront + fireplaces:landValue + livingArea:fireplaces + 
               bedrooms:fireplaces + pctCollege:landValue + bathrooms:landValue + 
               rooms:heating + bedrooms:fuel + bedrooms:waterfront + fuel:landValue + 
               heating:waterfront + pctCollege:fireplaces:landValue + bedrooms:fireplaces:waterfront,
             data = SaratogaHouses)

# Calculate size of train/test sets
n = nrow(SaratogaHouses)
n_train = round(0.8 * n)  # round to nearest integer
n_test = n - n_train

# Run KNN for increasing values of k
k_low_sh = 3
k_high_sh = 50
k_seq_sh = seq(k_low_sh, k_high_sh, by = 1)
n_trials_sh = 10

avg_RMSE_knn = do(n_trials_sh)* {
  RMSE_seq_sh = numeric(0)
  
  # Create train/test sets
  train_cases = sample.int(n, n_train, replace = FALSE)
  test_cases = setdiff(1:n, train_cases)
  saratoga_train = SaratogaHouses[train_cases,]
  saratoga_test = SaratogaHouses[test_cases,]
  
  # Construct the train/test set feature matrices
  x_train_KNN = model.matrix(~ . - sewer - landValue - newConstruction - 1,
                             data = saratoga_train)
  x_test_KNN = model.matrix(~ . - sewer - landValue - newConstruction - 1,
                            data = saratoga_test)
  # Train/test set responses
  y_train_KNN = saratoga_train$price
  y_test_KNN = saratoga_test$price
  
  # Rescale features so KNN works properly
  scale_train_KNN = apply(x_train_KNN, 2, sd)
  x_tilde_train_KNN = scale(x_train_KNN, scale_train_KNN)
  x_tilde_test_KNN = scale(x_test_KNN, scale_train_KNN)
  
  # Do KNN for different k values and record RMSE
  for (k in k_low_sh:k_high_sh) {
    knn = knn.reg(x_tilde_train_KNN, x_tilde_test_KNN, y_train_KNN, k)
    RMSE_seq_sh = c(RMSE_seq_sh, RMSE(y_test_KNN, knn$pred))
  }
  
  RMSE_seq_sh
}

data_avg_RMSE_knn = data.frame(avg_means = colMeans(avg_RMSE_knn), k_seq_sh)

# Choose the optimal value of k to minimize RMSE
optimal_k_sh = k_seq_sh[which.min(data_avg_RMSE_knn$avg_means)]

RMSE_vals = do(100)* {
  
  # Re-split into train and test cases with the same sample sizes
  train_cases = sample.int(n, n_train, replace = FALSE)
  test_cases = setdiff(1:n, train_cases)
  saratoga_train = SaratogaHouses[train_cases,]
  saratoga_test = SaratogaHouses[test_cases,]
  
  # Fit to the training data
  lm_orig = update(lm_orig, data = saratoga_train)
  
  # Additions:
  # waterfront decrease by ~$1800
  # age:livingArea decrease by ~$200
  # livingArea:centralAir decrease by ~$1000
  # livingArea:heating stabilizes decrease more
  # livingArea:fuel decrease by ~$250
  # fuel:centralAir decrease by ~$250
  # age:centralAir decrease by ~$100
  lm_new = update(lm_new, data = saratoga_train)
  lm_forward = update(lm_forward, data = saratoga_train)
  lm_step = update(lm_step, data = saratoga_train)
  
  # Fit KNN model with optimal K calculated above
  x_train_KNN = model.matrix(~ . - sewer - landValue - newConstruction - 1,
                             data = saratoga_train)
  x_test_KNN = model.matrix(~ . - sewer - landValue - newConstruction - 1,
                            data = saratoga_test)
  y_train_KNN = saratoga_train$price
  y_test_KNN = saratoga_test$price
  
  scale_train_KNN = apply(x_train_KNN, 2, sd)
  x_tilde_train_KNN = scale(x_train_KNN, scale_train_KNN)
  x_tilde_test_KNN = scale(x_test_KNN, scale_train_KNN)
  
  knn = knn.reg(x_tilde_train_KNN, x_tilde_test_KNN, y_train_KNN, optimal_k_sh)
  
  # Predictions out of sample
  yhat_test_orig = predict(lm_orig, saratoga_test)
  yhat_test_new = predict(lm_new, saratoga_test)
  yhat_test_forward = predict(lm_forward, saratoga_test)
  yhat_test_step = predict(lm_step, saratoga_test)
  
  orig = RMSE(saratoga_test$price, yhat_test_orig)
  new = RMSE(saratoga_test$price, yhat_test_new)
  forward = RMSE(saratoga_test$price, yhat_test_forward)
  step = RMSE(saratoga_test$price, yhat_test_step)
  knn_ = RMSE(y_test_KNN, knn$pred)
  
  c(orig, new, forward, step, knn_)
}

colnames(RMSE_vals) = c("Base Model",
                        "Hand-Built Model",
                        "Forward Selection Model",
                        "Step Selection Model",
                        "KNN Model")

avg_RMSE_vals = colMeans(RMSE_vals)
orig_RMSE_val = avg_RMSE_vals[1]

data_avg_RMSE_vals = data.frame(avg_RMSE_vals, 
                                diff_from_orig = abs(round(avg_RMSE_vals - orig_RMSE_val, 2)))

```

Table 3 - Additions in "Hand-Built" Model       | : means interactions
------------------- |---------------------------|-------------------------
Waterfront          | Age:Living Area           | Living Area:Central Air 
Living Area:Heating | Living Area:Fuel          | Fuel:Central Air
Age:Central Air     | Living Area:Fireplaces    | Rooms:Heating
Bedrooms:Fuel       | Living Area:Rooms         | Bedrooms:Bathrooms

```{r fig.align = 'center', echo = FALSE, message = FALSE, warning = FALSE}
# Plot RMSE vs. K
ggplot(data = data_avg_RMSE_knn) +
  geom_point(mapping = aes(x = k_seq_sh, y = avg_means)) +
  geom_path(mapping = aes(x = k_seq_sh, y = avg_means)) +
  geom_vline(xintercept = optimal_k_sh) +
  labs(title = "Saratoga Houses RMSE vs. K",
       x = "K",
       y = "RMSE",
       caption = "Figure 7: Curve showing average RMSE after 10 train/test splits for each value of K.
       The vertical line shows the K value with the lowest average RMSE.") + 
  theme(plot.title = element_text(hjust = 0.5),
        plot.caption = element_text(size = 10, hjust = 0.5))

ggplot(data = melt(as.data.frame(RMSE_vals))) +
  geom_boxplot(aes(x = variable, y = value, fill = variable)) +
  labs(title = "Distribution of RMSE by Model",
       y = "RMSE ($)",
       caption = "Figure 8: Boxplot showing the distribution of RMSE values of 100 train/test splits
       performed on each of the models created including the baseline model.") +
  theme(plot.title = element_text(hjust = 0.5),
        plot.caption = element_text(size = 10, hjust = 0.5),
        axis.title.x = element_blank(),
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        legend.title = element_blank())

data_avg_RMSE_vals %>%
  kable(caption = "Table 4: The performance gain of each model with respect to the baseline model
        measured by the difference in RMSE values",
        col.names = c("Average Model RMSE", 
                      "Improvement from Base Model")) %>%
  kable_styling(position = "center")
```

As shown both by Figure 8 and Table 4, the clear winner in terms of model performance is the KNN model using the optimal values of k = `r optimal_k_sh`. Though their performance was not as great as the KNN model, the other three models each help give insight into the nature of the data set and the general housing market. For example, the forward selection and step selection models, which incrementally improve a model by adding (and in the case of step selection, possibly removing) features and interactions, can be useful for potentially highlighting important relationships in the data that might not be easy to notice at the surface level. Despite their end products typically leading to a model that is very difficult to interpret, I found myself looking at the progression of models in the forward selection and step selection to help fine tune my "hand-built" model. When it comes to the "hand-built" model, its importance lies not in the mild performance gains, but in its simple interpretability. Out of the total features and interactions added (seen in Table 3), including main features such as the property being on a waterfront and interactions between living area and presence of central air-conditioning showed to be strong influences on the model and on house price. The "hand-built" model's gains in performance confirm some of the relatively intuitive ideas that price is influenced by features and interactions like these (being on a waterfront would likely increase prices and central air-conditioning would be much more valuable and important in larger living spaces).

<p>&nbsp;</p>

In conclusion, for the best predictions of the market value for houses, the KNN model showed to be by-and-large the most effective and is the one that should be used with performance in mind. However, the other models should not be totally disregarded for they have their own importance outside of strict ability to perform. 

<p>&nbsp;</p>

## Predicting When Articles Go Viral

Having an article go viral is a big deal, as it means spreading the message of the article to a far-reaching audience. Mashable, who wants to build a model to determine whether an article goes viral or not, would benefit greatly from this as they would be able to likely capitalize on it and have more viral posts. They would be able to predict whether or not the articles they write would go viral. More importantly however, an exemplary model would demystify the characteristics of an article that make it more likely to go viral.

<p>&nbsp;</p>

As the data set we are going to use to make these predictions consists of a hefty 39,797 online articles published on Mashable during 2013 and 2014, with each entry consisting of 38 different features about the article, I found it necessary to clean up the data set a bit to make it more manageable. My method of cleaning up the data set was by condensing down the number of variables, taking similar variables, like the 7 for each day of the week an article could have been published, and aggregating them. Additionally, I removed the url variable as it is meaningless to our analysis and added the viral variable based on Mashable's judgement that a viral article has greater than 1400 shares.

<p>&nbsp;</p>

Table 5 - Complete List of Variable Changes in Cleaning Data Set

Deletions                     | Additions
------------------------------|---------------
url                           | viral
data_channel_is_lifestyle     | news_channel
data_channel_is_entertainment |
data_channel_is_bus           |
data_channel_is_socmed        |
data_channel_is_tech          |
data_channel_is_world         |
weekday_is_monday             | day_published
weekday_is_tuesday            |
weekday_is_wednesday          |
weekday_is_thursday           |
weekday_is_friday             |
weekday_is_saturday           |
weekday_is_sunday             |

<p>&nbsp;</p>

There are two options on how to approach this problem, both of which will be done to compare the outcomes. The first option is doing a regression on the data set in order to build a predictive model for the values of shares. Then, predictions from this model can be thresholded where the article is predicted to go viral if the predicted value for shares is greater than 1400. The second option is doing the reverse, thresholding the data such that there is the binary viral (yes or no) feature now, and then performing classification to build a model that predicts if an article will go viral or not.

<p>&nbsp;</p>

Our workhorse modeling method for both of these approaches will be KNN. Unfortunately, because of the sheer number of features, even in the processed version of the data set, it is unfeasible in both space and time to do KNN regression on all the features. Therefore, I built my own model to run through KNN regression that uses the features from the data set that I believe would have the most influence on the share count. For example, I included title_subjectivity because I would think that posts with a higher subjectivity in their title would get shared more often. My complete choice of model is in Table 6. Additionally, to measure the performance of the models, a good null model is necessary. Upon examination of the data set, it appears that a little over half of the articles are not viral, so a null model that predicts all articles to be not viral would have an error rate of a little under half (see Table 7).

<p>&nbsp;</p>

Table 6 - Complete List of Features in KNN Regression Model | 
------------------------------------------------------------|----------------
news_channel                                                | num_keywords
title_sentiment_polarity                                    | num_hrefs
title_subjectivity                                          | num_self_hrefs
avg_negative_polarity                                       | days_published
self_reference_avg_sharess                                  | n_tokens_title 
                              
```{r include = FALSE}
online_news = read.csv("online_news.csv")

online_news = subset(online_news, select = -url)
online_news$viral = ifelse(online_news$shares > 1400, 1, 0)

news = online_news

news$news_channel = NA 
news$news_channel[news$data_channel_is_lifestyle == 1] = "Lifestyle"
news$news_channel[news$data_channel_is_entertainment == 1] = "Entertainment"
news$news_channel[news$data_channel_is_bus == 1] = "Business"
news$news_channel[news$data_channel_is_socmed == 1] = "Social Media"
news$news_channel[news$data_channel_is_tech == 1] = "Technology"
news$news_channel[news$data_channel_is_world == 1] = "World"
news$news_channel[is.na(news$news_channel)] = "Other"

news$news_channel = factor(news$news_channel, 
                           levels = c("Business", 
                                      "Entertainment", 
                                      "Lifestyle", 
                                      "Technology", 
                                      "World",
                                      "Social Media",
                                      "Other"))

news$day_published = NA
news$day_published [news$weekday_is_monday == 1] = "Monday"
news$day_published [news$weekday_is_tuesday == 1] = "Tuesday"
news$day_published [news$weekday_is_wednesday == 1] = "Wednesday"
news$day_published [news$weekday_is_thursday == 1] = "Thursday"
news$day_published [news$weekday_is_friday == 1] = "Friday"
news$day_published [news$weekday_is_saturday == 1] = "Saturday"
news$day_published [news$weekday_is_sunday == 1] = "Sunday"

news$day_published = factor(news$day_published, 
                             levels = c( "Monday", "Tuesday", "Wednesday", "Thursday",
                                         "Friday", "Saturday", "Sunday"))

removevars = c("data_channel_is_lifestyle",
                "data_channel_is_entertainment",
                "data_channel_is_bus",
                "data_channel_is_socmed",
                "data_channel_is_tech",  
                "data_channel_is_world",
                "weekday_is_monday",     
                "weekday_is_tuesday",    
                "weekday_is_wednesday",  
                "weekday_is_thursday",   
                "weekday_is_friday",     
                "weekday_is_saturday",   
                "weekday_is_sunday")

news = news[, !(colnames(news) %in% removevars)]

null_model = data.frame(c(nrow(news[news$shares <= 1400,]) / nrow(news), nrow(news[news$shares > 1400,]) / nrow(news)))
colnames(null_model) = "Proportion"
rownames(null_model) = c("Not Viral", "Viral")
```

```{r echo = FALSE}
kable(null_model, caption = "Table 7 - Null model should always predict not viral because it is more frequent") %>%
  kable_styling(position = "center")
```

<p>&nbsp;</p>

First is the KNN regression model, which predicts the shares of a news article. This prediction is then thresholded and compared against the actual viral status to determine the error rates.

```{r include = FALSE}
# Calculate size of train/test sets
n_news = nrow(news)
n_train_news = round(0.8 * n_news)

# Run KNN for increasing values of k
k_low_news = 3
k_high_news = 10
k_seq_news = seq(k_low_news, k_high_news, by = 1)
n_trials_news = 5

avg_succ_knn = do(n_trials_news)* {
  succ_seq_news = numeric(0)
  
  # Create train/test sets
  train_cases = sample.int(n_news, n_train_news, replace = FALSE)
  test_cases = setdiff(1:n_news, train_cases)
  news_train = news[train_cases,]
  news_test = news[test_cases,]
  
  # Construct the train/test set feature matrices
  x_train_KNN = model.matrix(~ news_channel + title_sentiment_polarity +
                               title_subjectivity + num_keywords +
                               avg_negative_polarity +
                               day_published + n_tokens_title +
                               self_reference_avg_sharess +
                               num_hrefs + num_self_hrefs - 1,
                             data = news_train)
  x_test_KNN = model.matrix(~  news_channel + title_sentiment_polarity +
                              title_subjectivity + num_keywords +
                              avg_negative_polarity +
                              day_published + n_tokens_title +
                              self_reference_avg_sharess +
                              num_hrefs + num_self_hrefs - 1,
                            data = news_test)
  # Train/test set responses
  y_train_KNN = news_train$shares
  y_test_KNN = news_test$viral
  
  # Rescale features so KNN works properly
  scale_train_KNN = apply(x_train_KNN, 2, sd)
  x_tilde_train_KNN = scale(x_train_KNN, scale_train_KNN)
  x_tilde_test_KNN = scale(x_test_KNN, scale_train_KNN)
  
  # Do KNN for different k values and record rmse
  for (k in k_low_news:k_high_news) {
    knn = knn.reg(x_tilde_train_KNN, x_tilde_test_KNN, y_train_KNN, k)
    
    confusion = table(y = y_test_KNN, yhat = ifelse(knn$pred > 1400, 1, 0))
    succ_seq_news = c(succ_seq_news, sum(diag(confusion)) / sum(confusion))
  }
  
  succ_seq_news
}

data_avg_succ_knn = data.frame(avg_means = colMeans(avg_succ_knn), k_seq_news)
max(data_avg_succ_knn$avg_means)
optimal_k = data_avg_succ_knn$k_seq_news[which.max(data_avg_succ_knn$avg_means)]

n_trials_news = 100
model_metric = do(n_trials_news)* {
  
  # Create train/test sets
  train_cases = sample.int(n_news, n_train_news, replace = FALSE)
  test_cases = setdiff(1:n_news, train_cases)
  news_train = news[train_cases,]
  news_test = news[test_cases,]
  
  # Construct the train/test set feature matrices
  x_train_KNN = model.matrix(~ news_channel + title_sentiment_polarity +
                               title_subjectivity + num_keywords +
                               avg_negative_polarity +
                               day_published + n_tokens_title +
                               self_reference_avg_sharess +
                               num_hrefs + num_self_hrefs - 1,
                             data = news_train)
  x_test_KNN = model.matrix(~  news_channel + title_sentiment_polarity +
                              title_subjectivity + num_keywords +
                              avg_negative_polarity +
                              day_published + n_tokens_title +
                              self_reference_avg_sharess +
                              num_hrefs + num_self_hrefs - 1,
                            data = news_test)
  # Train/test set responses
  y_train_KNN = news_train$shares
  y_test_KNN = news_test$viral
  
  # Rescale features so KNN works properly
  scale_train_KNN = apply(x_train_KNN, 2, sd)
  x_tilde_train_KNN = scale(x_train_KNN, scale_train_KNN)
  x_tilde_test_KNN = scale(x_test_KNN, scale_train_KNN)
  
  knn = knn.reg(x_tilde_train_KNN, x_tilde_test_KNN, y_train_KNN, k)
  
  confusion = table(y = y_test_KNN, yhat = ifelse(knn$pred > 1400, 1, 0))
   
  tot_error = 1 - sum(diag(confusion)) / sum(confusion)
  t_pos = confusion[4] / (confusion[2] + confusion[4])
  f_pos = confusion[3] / (confusion[1] + confusion[3])
  
  c(tot_error, t_pos, f_pos)
}

avg_rates = data.frame(colMeans(model_metric))
rownames(avg_rates) = c("Overall Error Rate", "True Positive Rate", "False Positive Rate")

total_errors = select(model_metric, V1)
```

```{r fig.align = 'center', echo = FALSE}
confusion %>%
  kable(caption = "Table 8: Confusion matrix for KNN regression model with horizontal predicted 
        values and vertical actual values.") %>%
  kable_styling(position = "center")

avg_rates %>%
  kable(caption = "Table 9: KNN regression model performance metrics.",
        col.names = NULL) %>%
  kable_styling(position = "center")

ggplot(data = total_errors) +
  geom_boxplot(mapping = aes(y = V1)) +
  geom_hline(yintercept = null_model[2, 1]) +
  labs(title = "Overall Error Rate for KNN Regression Model",
       y = "Overall Error Rate",
       caption = "Figure 9: Boxplot showing the distribution of overall error rates across 100 train/test splits
       on the KNN regression model. The black horizontal line is the null model's overall error rate.") +
  theme(plot.title = element_text(hjust = 0.5),
        plot.caption = element_text(size = 10, hjust = 0.5),
        axis.text.x =  element_blank(),
        axis.ticks.x = element_blank())
```

The KNN regression model with k = `r optimal_k` performs decently well compared to the null model, having an overall error rate `r null_model[2, 1] - avg_rates[1,1]` lower than the null model. It seems that the KNN regression model predicts higher shares than the actual share value, as seen by the high true positive and false positive rates. The model just seems to predict that articles will go viral very often, which is a bias that has to be taken into account, despite the low value of K.

<p>&nbsp;</p>

Next is the KNN classification model, which predicts if an article will go viral directly. This is done by thresholding the data first and then doing the classification of the data using KNN. Again, because of time and space constraints, the list of features I chose is very sparse (Table 10), which impacts the accuracy of the classification negatively. The computational explosion that KNN has is an unfortunate drawback of this powerful modeling method.

<p>&nbsp;</p>

Table 10 - Complete List of Features in KNN Classification Model | 
-----------------------------------------------------------------|---------------
title_subjectivity                                               | num_keywords
avg_negative_polarity                                            | online_news

```{r include = FALSE}
X = dplyr::select(online_news, title_subjectivity, num_keywords,
                  avg_negative_polarity)
y = online_news$viral
n = length(y)

# select a training set
n_train = round(0.8 * n)
n_test = n - n_train

# Choosing optimal k takes too long
# k_grid = seq(3, 101, by = 2)
# err_grid = foreach(k = k_grid,  .combine = 'c') %do% {
  # out = do(10)* {
    # train_ind = sample.int(n, n_train)
    # X_train = X[train_ind,]
    # X_test = X[-train_ind,]
    # y_train = y[train_ind]
    # y_test = y[-train_ind]
    
    # scale the training set features
    # scale_factors = apply(X_train, 2, sd)
    # X_train_sc = scale(X_train, scale = scale_factors)
    
    # scale the test set features using the same scale factors
    # X_test_sc = scale(X_test, scale = scale_factors)
    
    # Fit KNN models (notice the odd values of K)
    # knn_try = class::knn(train = X_train_sc, test = X_test_sc, cl = y_train, k = k)
    
    # Calculating classification errors
    # sum(knn_try != y_test) / n_test
  # } 
  # mean(out$result)
# }

# Appears to be optimal at k - 101
avg_succ_knn_c = do(10)* {
  train_ind = sample.int(n, n_train)
  X_train = X[train_ind,]
  X_test = X[-train_ind,]
  y_train = y[train_ind]
  y_test = y[-train_ind]
  
  # scale the training set features
  scale_factors = apply(X_train, 2, sd)
  X_train_sc = scale(X_train, scale = scale_factors)
  
  # scale the test set features using the same scale factors
  X_test_sc = scale(X_test, scale = scale_factors)
  
  # Fit KNN models (notice the odd values of K)
  knn_try = class::knn(train = X_train_sc, test = X_test_sc, cl = y_train, k = 101)
  
  confusion = table(y = y_test, yhat = knn_try)
  
  tot_error = 1 - sum(diag(confusion)) / sum(confusion)
  t_pos = confusion[4] / (confusion[2] + confusion[4])
  f_pos = confusion[3] / (confusion[1] + confusion[3])
  
  c(tot_error, t_pos, f_pos)
}

avg_rates_c = data.frame(colMeans(avg_succ_knn_c))
rownames(avg_rates_c) = c("Overall Error Rate", "True Positive Rate", "False Positive Rate")

total_errors = select(avg_succ_knn_c, V1)
```

```{r fig.align = 'center', echo = FALSE}
confusion %>%
  kable(caption = "Table 11: Confusion matrix for KNN classification model with horizontal predicted 
        values and vertical actual values.") %>%
  kable_styling(position = "center")

avg_rates_c %>%
  kable(caption = "Table 12: KNN classification model performance metrics.",
        col.names = NULL) %>%
  kable_styling(position = "center")

ggplot(data = total_errors) +
  geom_boxplot(mapping = aes(y = V1)) +
  geom_hline(yintercept = null_model[2, 1]) +
  labs(title = "Overall Error Rate for KNN Regression Model",
       y = "Overall Error Rate",
       caption = "Figure 10: Boxplot showing the distribution of overall error rates across 10 train/test splits
       on the KNN classification model. The black horizontal line is the null model's overall error rate.") +
  theme(plot.title = element_text(hjust = 0.5),
        plot.caption = element_text(size = 10, hjust = 0.5),
        axis.text.x =  element_blank(),
        axis.ticks.x = element_blank())
```

The KNN classification model with k = 101 does not perform as well compared to the null model as the regression model did, having an overall error rate `r null_model[2, 1] - avg_rates_c[1,1]` lower than the null model. Unlike the KNN regression model, the KNN classification model had true and false positive rates that were on the underside of 0.5. Looking at the confusion matrix in Table 11, the model has nearly equal proportions in all four cells. A possible reason why this model underperformed was both because the features of its underlying model were not as strong, and because calculating the optimal K value requires too much time to feasibly do.

<p>&nbsp;</p>

Though these models did not give us significant improvements in classification accuracy compared to the null model, I believe we still learned a little about what features might improve an article's chance of reaching the threshold to be viral. The model that was built for the KNN regression (Table 6) was able to improve the accuracy by 4-6% on average, indicating that those features should be having some effect on the shares an article gets. When it comes to which model, the regression or the classification, performed better, they can not be fairly compared because the features they were using were different because of time and space constraints. However, intuitively, I would believe that the regression first and threshold second paradigm would have better performance because thresholding first causes the classification to be on the basis of a binary decision, viral or not viral. With regression, there is much more possibility for details to be included as classification as viral simply required shares to be above the threshold. In the end, it turns out deciding whether or not an article will go viral based on its features is much more complicated and difficult than it seems, but these KNN models were a starting point at attempting to learn more about the nature of viral posts on Mashable.